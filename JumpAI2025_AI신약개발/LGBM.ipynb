{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SqS9WWE2RQqq"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5gBa-wnTgsh"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbYhEG2QrLpA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, DataStructs, Descriptors\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "CFG = {\n",
        "    'NBITS': 2048,\n",
        "    'SEED': 42,\n",
        "    'N_SPLITS': 5,\n",
        "    'N_TRIALS': 50\n",
        "}\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed_everything(CFG['SEED'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in6wPxTvdRn7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/Colab Notebooks/Dacon/jumpAI2025/open.zip\"\n",
        "extract_path = \"/content/\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "chembl = pd.read_csv(\"ChEMBL_ASK1(IC50).csv\", sep=';')\n",
        "pubchem = pd.read_csv(\"Pubchem_ASK1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TO8hilekMMI"
      },
      "outputs": [],
      "source": [
        "# SMILES 데이터를 분자 지문으로 변환\n",
        "def smiles_to_fingerprint(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=CFG['NBITS'])\n",
        "        return np.array(fp)\n",
        "    else:\n",
        "        return np.zeros((CFG['NBITS'],))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDoQ29-hkOt2"
      },
      "outputs": [],
      "source": [
        "def IC50_to_pIC50(ic50_nM):\n",
        "    ic50_nM = np.clip(ic50_nM, 1e-10, None)\n",
        "    return 9 - np.log10(ic50_nM)\n",
        "def pIC50_to_IC50(pIC50):\n",
        "    return 10 ** (9 - pIC50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn6aHau0hkpZ"
      },
      "outputs": [],
      "source": [
        "chembl.columns = chembl.columns.str.strip().str.replace('\"', '')\n",
        "chembl = chembl[chembl['Standard Type'] == 'IC50']\n",
        "chembl = chembl[['Smiles', 'Standard Value']].rename(columns={'Smiles': 'smiles', 'Standard Value': 'ic50_nM'}).dropna()\n",
        "chembl['ic50_nM'] = pd.to_numeric(chembl['ic50_nM'], errors='coerce')\n",
        "chembl['pIC50'] = IC50_to_pIC50(chembl['ic50_nM'])\n",
        "\n",
        "pubchem = pubchem[['SMILES', 'Activity_Value']].rename(columns={'SMILES': 'smiles', 'Activity_Value': 'ic50_nM'}).dropna()\n",
        "pubchem['ic50_nM'] = pd.to_numeric(pubchem['ic50_nM'], errors='coerce')\n",
        "pubchem['pIC50'] = IC50_to_pIC50(pubchem['ic50_nM'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WybOhzjSksfV"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([chembl, pubchem], ignore_index=True)\n",
        "df = df.drop_duplicates(subset='smiles')\n",
        "df = df[df['ic50_nM'] > 0].dropna()\n",
        "df['Fingerprint'] = df['smiles'].apply(smiles_to_fingerprint)\n",
        "df = df[df['Fingerprint'].notnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNdEp45ZsXem"
      },
      "outputs": [],
      "source": [
        "# calculate_rdkit_descriptors\n",
        "def calculate_rdkit_descriptors(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None: return np.full((len(Descriptors._descList),), np.nan)\n",
        "    descriptors = [desc_func(mol) for _, desc_func in Descriptors._descList]\n",
        "    return np.array(descriptors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuAjgP0ms1ez"
      },
      "outputs": [],
      "source": [
        "def get_score(y_true_ic50, y_pred_ic50, y_true_pic50, y_pred_pic50):\n",
        "    rmse = mean_squared_error(y_true_ic50, y_pred_ic50, squared=False)\n",
        "    nrmse = rmse / (np.max(y_true_ic50) - np.min(y_true_ic50))\n",
        "    A = 1 - min(nrmse, 1)\n",
        "    B = r2_score(y_true_pic50, y_pred_pic50)\n",
        "    score = 0.4 * A + 0.6 * B\n",
        "    return score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJjIdZSk875"
      },
      "source": [
        "TRAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7dW-MgakwCK"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "def objective(trial, X, y):\n",
        "    params = {\n",
        "        'objective': 'regression', 'metric': 'rmse', 'verbose': -1, 'n_jobs': -1,\n",
        "        'seed': CFG['SEED'], 'boosting_type': 'gbdt', 'n_estimators': 2000,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
        "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
        "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
        "    }\n",
        "\n",
        "    kf = KFold(n_splits=CFG['N_SPLITS'], shuffle=True, random_state=CFG['SEED'])\n",
        "    oof_preds = np.zeros(len(X))\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X, y):\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "        model = lgb.LGBMRegressor(**params)\n",
        "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
        "                  eval_metric='rmse', callbacks=[lgb.early_stopping(100, verbose=False)])\n",
        "        oof_preds[val_idx] = model.predict(X_val)\n",
        "\n",
        "    y_ic50_true = pIC50_to_IC50(y)\n",
        "    oof_ic50_preds = pIC50_to_IC50(oof_preds)\n",
        "    score = get_score(y_ic50_true, oof_ic50_preds, y, oof_preds)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8oDY6x8tMBi"
      },
      "outputs": [],
      "source": [
        "print(\"1. Loading and preprocessing data...\")\n",
        "train_df = df.copy()\n",
        "if train_df is not None:\n",
        "    train_df['pIC50'] = IC50_to_pIC50(train_df['ic50_nM'])\n",
        "    print(\"\\n--- Feature Engineering ---\")\n",
        "    train_df['fingerprint'] = train_df['smiles'].apply(smiles_to_fingerprint)\n",
        "    train_df['descriptors'] = train_df['smiles'].apply(calculate_rdkit_descriptors)\n",
        "    train_df.dropna(subset=['fingerprint', 'descriptors'], inplace=True)\n",
        "\n",
        "    desc_stack = np.stack(train_df['descriptors'].values)\n",
        "    desc_mean = np.nanmean(desc_stack, axis=0)\n",
        "    desc_stack = np.nan_to_num(desc_stack, nan=desc_mean)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    desc_scaled = scaler.fit_transform(desc_stack)\n",
        "    fp_stack = np.stack(train_df['fingerprint'].values)\n",
        "    X = np.hstack([fp_stack, desc_scaled])\n",
        "    y = train_df['pIC50'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lC7Q3myk_FB"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Starting Hyperparameter Optimization with Optuna ---\")\n",
        "study = optuna.create_study(direction='maximize', study_name='lgbm_tuning')\n",
        "study.optimize(lambda trial: objective(trial, X, y), n_trials=CFG['N_TRIALS'])\n",
        "\n",
        "print(f\"\\nOptimization Finished. Best Score: {study.best_value:.4f}\")\n",
        "print(\"Best Parameters:\", study.best_params)\n",
        "\n",
        "best_params = { 'objective': 'regression', 'metric': 'rmse', 'verbose': -1, 'n_jobs': -1,\n",
        "                'seed': CFG['SEED'], 'boosting_type': 'gbdt', 'n_estimators': 2000 }\n",
        "best_params.update(study.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA8DjAkSuR__"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Training Final Model with Best Parameters ---\")\n",
        "test_df = pd.read_csv(\"./test.csv\")\n",
        "test_df['fingerprint'] = test_df['Smiles'].apply(smiles_to_fingerprint)\n",
        "test_df['descriptors'] = test_df['Smiles'].apply(calculate_rdkit_descriptors)\n",
        "\n",
        "valid_test_mask = test_df['fingerprint'].notna() & test_df['descriptors'].notna()\n",
        "fp_test_stack = np.stack(test_df.loc[valid_test_mask, 'fingerprint'].values)\n",
        "desc_test_stack = np.stack(test_df.loc[valid_test_mask, 'descriptors'].values)\n",
        "desc_test_stack = np.nan_to_num(desc_test_stack, nan=desc_mean)\n",
        "desc_test_scaled = scaler.transform(desc_test_stack)\n",
        "X_test = np.hstack([fp_test_stack, desc_test_scaled])\n",
        "\n",
        "kf = KFold(n_splits=CFG['N_SPLITS'], shuffle=True, random_state=CFG['SEED'])\n",
        "test_preds = np.zeros(len(X_test))\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
        "    print(f\"--- Training Fold {fold+1}/{CFG['N_SPLITS']} ---\")\n",
        "    X_train, y_train = X[train_idx], y[train_idx]\n",
        "    model = lgb.LGBMRegressor(**best_params)\n",
        "    model.fit(X_train, y_train)\n",
        "    test_preds += model.predict(X_test) / CFG['N_SPLITS']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTpz3hUUmloe"
      },
      "source": [
        "SUBMISSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEIV-nUAmm1N"
      },
      "outputs": [],
      "source": [
        "print(\"\\n3. Generating submission file...\")\n",
        "submission_df = pd.read_csv(\"./sample_submission.csv\")\n",
        "pred_df = pd.DataFrame({'ID': test_df.loc[valid_test_mask, 'ID'], 'ASK1_IC50_nM': pIC50_to_IC50(test_preds)})\n",
        "submission_df = submission_df[['ID']].merge(pred_df, on='ID', how='left')\n",
        "submission_df['ASK1_IC50_nM'].fillna(train_df['ic50_nM'].mean(), inplace=True)\n",
        "submission_df.to_csv(\"lgbm_tuned_submission.csv\", index=False)\n",
        "print(\"Submission file\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
