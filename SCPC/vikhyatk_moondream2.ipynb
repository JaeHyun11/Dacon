{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "hx2K4ctubth2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "MODEL_NAME = \"vikhyatk/moondream2\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "\n",
        "MODEL_NAME,\n",
        "\n",
        "trust_remote_code=True,\n",
        "\n",
        "torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f\"모델: {MODEL_NAME}\")\n",
        "print(f\"총 파라미터 수: {total_params:,}\")\n",
        "\n",
        "# 백만(Million), 십억(Billion) 단위 출력\n",
        "if total_params >= 1_000_000_000:\n",
        "    print(f\"{total_params / 1_000_000_000:.2f}B (십억) 개의 파라미터\")\n",
        "else:\n",
        "    print(f\"{total_params / 1_000_000:.2f}M (백만) 개의 파라미터\")"
      ],
      "metadata": {
        "id": "BAvBn0pLzers"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IIawAT4k8PyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoProcessor\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "base_path = \"/content/drive/MyDrive/Colab Notebooks/Dacon/SCPC/\"\n",
        "\n",
        "zip_path = os.path.join(base_path, 'data/open.zip')\n",
        "extract_path = '/content/data'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "print(f\"Extracting {zip_path} to {extract_path}...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Extraction complete.\")"
      ],
      "metadata": {
        "id": "jsur76Og7kae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_PATH = \"vikhyatk/moondream2\"\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "print(\"Loading model and processor...\")\n",
        "\n",
        "# Moondream2 모델 로드\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16, # or \"auto\"\n",
        "    device_map={\"\": device}\n",
        ")\n",
        "\n",
        "# 프로세서(토크나이저 포함) 로드\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH)\n",
        "extract_path = '/content/data'\n",
        "TEST_CSV_PATH = os.path.join(extract_path, 'test.csv')\n",
        "TEST_IMG_DIR = os.path.join(extract_path, 'test_input_images')\n",
        "SUBMISSION_PATH = os.path.join('/content/data', 'submission2.csv')\n",
        "test_df = pd.read_csv(TEST_CSV_PATH)"
      ],
      "metadata": {
        "id": "1xSyEVEPxVjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for index, row in tqdm(test_df.iterrows(), total=test_df.shape[0], desc=\"Predicting\"):\n",
        "    img_path = os.path.join(TEST_IMG_DIR, row['img_path'].split('/')[-1])\n",
        "    question = row['Question']\n",
        "    options = {'A': row['A'], 'B': row['B'], 'C': row['C'], 'D': row['D']}\n",
        "\n",
        "    try:\n",
        "        image = Image.open(img_path)\n",
        "    except FileNotFoundError:\n",
        "        # 이미지를 찾을 수 없는 경우, 건너뛰거나 기본값 처리\n",
        "        results.append({'ID': row['ID'], 'answer': 'A'}) # 기본값으로 'A' 선택\n",
        "        print(f\"Warning: Image not found at {img_path}. Defaulting to 'A'.\")\n",
        "        continue\n",
        "\n",
        "    # 프롬프트 구성\n",
        "    prompt = f\"Question: {question}\\nOptions:\\nA: {options['A']}\\nB: {options['B']}\\nC: {options['C']}\\nD: {options['D']}\\nBased on the image, which option is correct? Please provide only the letter of the correct option.\"\n",
        "\n",
        "    # 답변 생성\n",
        "    generated_answer = model.answer_question(\n",
        "        image,\n",
        "        prompt,\n",
        "        tokenizer=processor\n",
        "    )\n",
        "\n",
        "    # 생성된 답변 후처리 및 선택\n",
        "    final_choice = ''\n",
        "    # 답변을 대문자로 변환하고 공백 제거\n",
        "    processed_text = generated_answer.strip().upper()\n",
        "\n",
        "    # 답변에 선택지 텍스트가 그대로 포함되어 있는지 확인\n",
        "    for choice, text in options.items():\n",
        "        if text.upper() in processed_text:\n",
        "            final_choice = choice\n",
        "            break\n",
        "\n",
        "    # 만약 위에서 선택되지 않았다면, 답변에 알파벳 문자가 직접 포함되어 있는지 확인\n",
        "    if not final_choice:\n",
        "        # 정규식을 사용해 'A', 'B', 'C', 'D' 문자를 찾음\n",
        "        found_letters = re.findall(r'\\b[A-D]\\b', processed_text)\n",
        "        if found_letters:\n",
        "            final_choice = found_letters[0]\n",
        "\n",
        "    # 그래도 선택되지 않았다면, 기본값 'A'로 설정\n",
        "    if not final_choice:\n",
        "        final_choice = 'A'\n",
        "\n",
        "    results.append({'ID': row['ID'], 'answer': final_choice})\n",
        "\n",
        "print(\"\\nPrediction complete.\")"
      ],
      "metadata": {
        "id": "ajNdzJR_7ozc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과를 DataFrame으로 변환\n",
        "submission_df = pd.DataFrame(results)\n",
        "\n",
        "# 결과 확인\n",
        "print(\"\\n--- Generated Submission File (Top 5) ---\")\n",
        "print(submission_df.head())\n",
        "\n",
        "# CSV 파일로 저장\n",
        "submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
        "\n",
        "print(f\"Submission file saved successfully at '{SUBMISSION_PATH}'\")"
      ],
      "metadata": {
        "id": "EiNOmKyA8cC2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}